---
title: 'Information-Content-Informed Kendall-tau Correlation: Utilizing Missing Values'
author: 'Robert M Flight & Hunter NB Moseley'
date: '`r Sys.time()`'
output: 
  rmarkdown::word_document
bibliography: '`r here::here("doc/icikt_references.json")`'
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.width = 8, fig.height = 6)

increment_count = function(in_object, id_name){
  n_obj = length(in_object)
  use_number = max(in_object) + 1
  in_object = c(in_object, use_number)
  names(in_object)[n_obj + 1] = id_name
  in_object
}

paste_label = function(pre_text, in_object, id_name){
  object_number = in_object[id_name]
  
  use_text = paste(pre_text, object_number, sep = " ")
  
  use_text
}

figure_count = c("_" = 0)
table_count = c("_" = 0)
```

## Abstract

Almost all correlation measures currently available are unable to handle missing values.
Typically, missing values are either ignored completely by removing them or are imputed and used in the calculation of the correlation coefficient.
In both cases, the correlation value will be impacted based on a perspective that missing data represents no useful information.
However, missing values occur in real data sets for a variety of reasons. 
In -omics data sets that are derived from analytical measurements, the primary reason is that a specific measureable phenomenom falls below the detection limits of the analytical instrumentation.
Therefore, these missing data are not missing at random, but represent some information by their "missingness".
Therefore, we propose an information-content-informed Kendall-tau (ICI-Kt) correlation coefficient that allows missing values to carry explicit information in determination of concordant and discordant pairs.
With both simulated and real data sets from RNA-seq experiments, we demonstrate that the ICI-Kt allows for the inclusion of missing data values as interpretable information.
Moreover, our implementation of ICI-Kt uses a mergesort-like algorithm that provides nlog(n) computational performance. 
Finally, we show that approximate ICI-Kt values can be calculated using smaller subsets of large data sets with significant time savings, which has practical computational value when feature sizes are very large.

The ICI-Kt correlation calculation is available in an R package on GitHub at https://moseleyBionformaticsLab/ICIKendallTau.

## Introduction

Correlation as a measure of the relatedness or similarity of two or more sets of data has a long history, with the mathematical technique being used (and abused) in various scientific fields since it's introduction [@pearson_notes_1920; @rodgers_13_1988].
More recently, correlation calculations have become a cornerstone statistical method in the analysis and integration of varied -omics' datasets, especially the big 5 omics: genomics, transcriptomics, proteomics, metabolomics, epigenomics [@gu_complexheatmap_2016].
Correlation between biomolecular features (nucleotide variants, RNA transcripts, proteins, metabolites) may be used to determine the relationship between pairs of the features as well as to detect and derive correlative structures between groups of features [@fukushima_integratedomics_2009].
Moreover, correlation is a foundational method for generating biomolecular feature - feature interaction networks, like those provided by STRING [@szklarczyk_string_2017], Genemania [@franz_genemania_2018], and WCGNA [@langfelder_wgcna_2008].
Feature - feature correlation may also be used to inform which features are used for imputation of missing values [@faquih_missingvalueworkflow_2020].
Correlation of samples in -omics may be used for evaluating whether all the samples from a particular condition are truly related to each other, as well as to inform the choice of analysis, and to check for outliers prior to other statistical analysis [@flight_timecourseexploration_2010; @gierlinski_statisticalmodels_2015].

However, all analytical methods, and in particular the analytical methods used in -omics where so many analytes are being measured simultaneously; suffer from missing measurements.
Of course some analytes will be missing at random just because of some issue with the instrument or that particular sample, but a large amount of missing measurements are left-censored due to analytes being below the effective detection limit of the instrument, as shown in Figure 1.
Some analytical instruments are actually purposely designed to floor measurements, when they occur below a certain signal to noise ratio threshold.
Imputation of missing measurements in -omics samples is an active area of research, which we will not cover here beyond to say that it is worthwhile and very necessary in many instances.
But when it comes to calculating correlation, there are very few methods that explicitly account for missing data that we know of.
In many cases, missing values may be imputed to zero (or another value) and then included in the correlation calculation.
Imputation or replacement with zero is likely to lead to high inflation of Pearson and related correlation measures.
Other approaches keep only those features with no missing values across samples (complete cases), or keep non-missing between any pair of samples (pairwise complete cases).
Each of these are likely to mis-estimate the real sample - sample correlation values, especially from specific data interpretation perspectives.

```{r include_figure1}
knitr::include_graphics(here::here("doc/the_problem.png"))
```

Figure 1. Graphical description of the left-censored data problem.
The true analyte concentration range covers the full range of the density distribution, with the minimum on the left, and the maximum on the right.
An example density plot of the analyte concentrations for a single sample is shown as a solid line, and the instrument response to concentration as a dashed line.
Below certain analyte concentrations, highlighted as the red region, the instrument returns **0** or **missing** values.
Above certain concentrations, highlighted as the yellow region, all values returned will also be identical (or flagged depending on the instrument).
Which analytes will have concentrations in the red region may vary from sample to sample due to the overall sample composition, as well as natural variances within each sample.

Assuming that a majority of missing values are **not missing at random**, but rather result from left-censored distributions due to the analyte being below the effective detection limit (see Figure 1), we propose that these missing values do in fact encode useful information that can be incorporated into correlation calculations, especially the Kendall-tau paired rank correlation coefficient.
In this manuscript, we propose new definitions of concordant and discordant rank pairs that include missing values, as well as methods for incorporating missing values into the number of tied values for the equivalent of the modified Kendall-tau coefficient.
We examine the effect of missing values on simulated data, comparing our information-content-informed Kendall-tau (ICI-Kt) method with other simpler methods of handling the missing values, namely removing them or imputing them to zero.
Finally, we examine the ability to recapitulate ICI-Kt correlation values calculated on a large feature -omics data set using feature subsets, which is useful as the run time of very large feature data sets can become prohibitive.

## Methods

### Definition of Concordant and Discordant Pairs

In the simplest form, the Kendall-tau correlation can be defined as:

$$\tau = \frac{ | pairs_{concordant}  | - | pairs_{discordant}  |}{\left | pairs_{concordant} \right | + \left | pairs_{discordant} \right |}$$
**NEED to discuss this definition with Hunter**.In this case a **pair** are any two $x$ and $y$ points from two different samples, consisting of $(x_i, x_j)$ and $(y_i, y_j)$.
A concordant pair has the following classical definition:

  * $x_i > x_j$ and $y_i > y_j$ 
  * $x_i < x_j$ and $y_i < y_j$

A discordant pair has the following classical definition [@kendall_newmeasure_1938]:

  * $x_i > x_j$ and $y_i < y_j$
  * $x_i < x_j$ and $y_i > y_j$

Assuming that the majority of missing values are not missing at random, but due to being below the effective detection limit, we can expand the concordant and discordant pair definitions to include missing values. Here $!x$ indicates a missing value and & is synonymous with "and".
The information-content-informed concordant pair definitions are below:

  * $x_i > x_j$ and $y_i > y_j$
  * $x_i < x_j$ and $y_i < y_j$
  * $x_i > x_j$ and $y_i \& !y_j$
  * $x_i < x_j$ and $!y_i \& y_j$
  * $x_i \& !x_j$ and $y_i > y_j$
  * $!x_i \& x_j$ and $y_i < y_j$ 
  * $x_i \& !x_j$ and $y_i \& !y_j$ 
  * $x_i \& x_j$ and $!y_i \& y_j$ 
  
The information content informed discordant pair definitions are below:

  * $x_i > x_j$ and $y_i < y_j$ 
  * $x_i < x_j$ and $y_i > y_j$
  * $x_i > x_j$ and $!y_i \& y_j$ 
  * $x_i < x_j$ and $y_i \& !y_j$
  * $x_i \& !x_j$ and $y_i < y_j$
  * $!x_i \& x_j$ and $y_i > y_j$
  * $x_i \& !x_j$ and $!y_i \& y_j$
  * $!x_i \& x_j$ and $y_i \& !y_j$

### Considering Ties

Tied values do not contribute to either of the concordant or discordant pair counts, and the original Kendall-tau formula which calculates the tau-a statistic does not consider the presence of tied values.
However, the related tau-b statistic does handle the presence of tied values by adding the tied $x$ and $y$ values to the denominator, and in our special case of missing data, we can add the ties that result from both of $(x_i, x_j)$ and $(y_i, y_j)$ being missing [@kendall_treatment_ties_1945; @kendall_rankcorrelationbook_1948].

$$\tau = \frac{\left | pairs_{concordant} \right | - \left | pairs_{discordant} \right |}{\sqrt{(n_0 - n_{xtie})(n_0 - n_{ytie})}}$$

In the first instance, we remove those x-y points where both values are missing.
We refer to this case as the "local" ICI-Kt correlation.
It is most appropriate for the comparison of only two samples, where we are concerned with what values are present in the two samples, with the odd case of missingness.

The other case, where we leave ties resulting from points with missing $x$ and $y$, we refer to as the "global" ICI-Kt correlation.
In this case, every single sample-sample correlation will consider the same number of pair comparisons.
This is more useful when analyzing and interpreting correlations across multiple samples, not just two feature vectors.

### Theoretical Maxima

The "global" case also provides an interesting property, whereby we can calculate the theoretical maximum correlation that would be possible to observe given the lowest number of shared missing values.
This value can be useful to scale the rest of the observed correlation values across many sample - sample correlations, providing a value that scales an entire dataset appropriately.

$$cor_{max} = \frac{\binom{n-m}{2} + n * m}{\binom{n-m}{2} + n * m + \binom{m}{2}}$$
To calculate the theoretical maximum correlation for rescaling, we choose the two samples with the least number of missing values across the dataset.
Then $n$ is the length of the variables, $m$ is the count of missing values across the two samples divided by two and rounded towards zero.

### Implementation Details

We produced an initial reference implementation in R [@rcoreteam_rlanguage_2020] where the various concordant and discordant pair definitions were written as simple logical tests to allow further exploration and validation of faster implementations.
In practice, it is possible to replace the missing values with a value that is smaller than all of the values in the two sets of values under consideration, and then do tests of signs to define concordant and discordant pairs (see the definitions of concordant and discordant pairs above).

After this initial implementation, we used the SciPy [@virtanen_scipy_2020] kendalltau code as a model to create a mergesort based implementation that has a complexity of O(nlog(n)), in comparison to the pairwise testing that has a complexity of O(n^2) [@knight_mergesortkendall_1966].
This provides a 460X speedup of the runtime to compare two feature vectors with lengths of 40,000.
In comparison to directly counting the concordant and discordant pairs, some of the values in the mergesort implementation can reach the 32 bit default limit in C++.
Therefore, we used 64 bit integers and floats where necessary in the Rcpp code.

C++ (via *Rcpp* [@eddelbuettel_rcppseamless_2011; @eddelbuettel_seamlessbook_2013; @eddelbuettel_extendingrcpp_2018]) and R code implementations are in the src/kendallc.cpp and R/kendalltau.R files of the ICIKendallTau R package, hosted at https://github.com/MoseleyBioinformaticsLab/ICIKendallTau.
The version of the package used in this manuscript is available on figshare.

### Simulated Data Sets

Simulated feature vectors (analytical samples) are generated by drawing 1000 random values from a log-normal distribution with a mean of 1 and sd of 0.5 and sorting them in ascending order.
The negative analytical sample has values sorted in descending order.
Missing value indices are generated by randomly sampling up to 499 of the lowest values in each sample.
For the negative sample, the indices are also subtracted from 1000 to cause them to be at the lower end of the feature distribution.
Finally, missing indices were only inserted into one of the two samples being compared before calculating the correlation.
The missing indices are replaced with NA, and then correlations between the analytical samples are calculated.

Another, more realistic, simulated data set is generated by drawing 1000 random values from a log-normal distribution, and adding noise from a normal distribution with a mean of zero and standard deviation of 0.2 to create two statistical samples.
Missing values are created in these statistical samples via two methods: 1) by creating intensity cutoffs from 0 to 1.5 in 0.1 increments, values below the cutoff set to missing or zero depending on the calculation; 2) randomly sampling locations in the two-sample matrix ranging from zero to 300 in increments of 50 and setting the indices to missing or zero.

### EGFR RNA-Seq Data Set

RNA-Seq dataset from null and knock-in EGFR mice mutants. **going to need more than this**.

### Adenocarcinoma Recount RNA-Seq Data Set

We downloaded the V2 Recount lung cancer data [@collado-torres_recount2_2017], extracted the scaled counts, and trimmed to the Stage I adenocarcinoma samples, and those genes that have a non-zero count in at least one of the samples.

Pearson and Kendall correlations are calculated with zero, as well as replacing zero values with NA.

### Multiprocessing

When a large number of samples need to be compared, it may be useful to split the comparisons across compute instances (across hyperthreaded cores, physical cores, or physical compute nodes).
The *furrr* R package makes the definition of compute clusters easy.
For a large correlation matrix computation, we first define the sample - sample comparisons to be performed, then check how many instances of compute are available (defined by a previous call to *furrr*), and finally split the comparisons into a list that can be easily distributed using the *furrr::future_map* function.

### Subsampling of Features

In addition to using the full set of features to calculate sample - sample correlations, it is possible to select a subsample of features and only use this feature subset to calculate correlations.
Three methods were implemented: 1) random selections; 2) top set of features by variance; and 3) top set of features by variance of principal components.

For (1), random selection, feature subsamples of 1 - 10% by 1% increments, and then in 5% increments to 90% were taken using the *sample* R function.
For (2), selection by variance, feature variances across samples were calculated, and then ranked by the variances.
For (3), selection by variance of the principal components, principal component analysis (PCA) decomposition was performed on the full data set, the variance contribution of each PC calculated, and then the percent variance for each principal component (PC) is used to determine the number of features with high loadings to select from the given PC.
In this feature subsampling approach, weaker PCs contribute proportionately fewer features to the feature subset.

### Principal Component Evaluation of Subsample Coverage

The principal component decomposition of the full adenocarcinoma dataset was used to define the loadings for each principal component.
For a given principal component (PC), the sum of the absolute values of the loadings defines the total loadings for that PC.
The absolute values of the loadings for the subsampled features are also summed, and then divided by the total loadings previously calculated using all features.
The loading fraction is calculated for each subsample of features, across all PCs.
The responsible variance for each PC was also calculated as the variance of the scores in each PC.
Further, the Kendall-tau correlation between the loading fraction and the PC variances was calculated.
The median loading fraction across all PCs was also calculated, as well as fractional difference of the median loading fraction to the intended fraction (the number of subsampled features over the total number of features).


### Computing Environment

Most calculations were run on a virtual machine with 80 virtual cores, and 1 TB of RAM.
The virtual machine is running on top of a 50 node cluster, each with 4 10-core processors, 3TB of RAM and an 8TB solid-state-drive array, provided by the Kentucky Research Informatics Cloud (KyRIC).
KyRIC manages the virtual machines via an OpenStack instance.
We used the *drake* package to manage calculation dependencies [@landau_drakepackage_2018].
For the comparisons of time taken using different numbers of samples to evaluate the algorithmic complexity, calculations were run on a single laptop Intel i7 core clocked at 2.2 GHz.

## Results


### Comparison To Other Correlation Measures

We compared the ICI-Kt correlation to both Pearson and regular Kendall-tau-b correlations as calculated by the built-in R functions using simulated data sets with missing values, as well as a large RNA-seq dataset.

We created two samples with 1000 observations each drawn from a log-normal distribution, and sorted in each case.
The *true* correlation for each of the Kendall and Pearson correlations were calculated, and then missingness was introduced in the lower range of values (see Methods).

```{r compare_realistic, fig.width = 8, fig.height = 8}
loadd(realistic_sample_1)
loadd(realistic_sample_2)
loadd(realistic_neg_sample)
ref_pearson = cor(realistic_sample_1, realistic_sample_2)
ref_kendall = ici_kt(realistic_sample_1, realistic_sample_2, "global")[1]

ref_pearson_neg = cor(realistic_sample_1, realistic_neg_sample)
ref_kendall_neg = ici_kt(realistic_sample_1, realistic_neg_sample, "global")[1]

loadd(realistic_na)
n_na = purrr::map_int(realistic_na, length)
loadd(realistic_positive_pearson)
loadd(realistic_positive_kendall)
loadd(realistic_positive_kt)
loadd(realistic_negative_pearson)
loadd(realistic_negative_kendall)
loadd(realistic_negative_kt)

realistic_positive_pearson = realistic_positive_pearson %>%
  dplyr::mutate(type = "Pearson",
                dir = "positive",
                diff = ref_pearson - cor,
                n_na = (x_na + y_na) / 2)

realistic_negative_pearson = realistic_negative_pearson %>%
  dplyr::mutate(type = "Pearson",
                dir = "negative",
                diff = ref_pearson_neg - cor,
                n_na = (x_na + y_na) / 2)

realistic_positive_kendall = realistic_positive_kendall %>%
  dplyr::mutate(type = "Kendall",
                dir = "positive",
                diff = ref_kendall - cor,
                n_na = (x_na + y_na) / 2)

realistic_negative_kendall = realistic_negative_kendall %>%
  dplyr::mutate(type = "Kendall",
                dir = "negative",
                diff = ref_kendall_neg - cor,
                n_na = (x_na + y_na) / 2)

realistic_positive_kt = realistic_positive_kt %>%
  dplyr::mutate(type = "ICI-Kt",
                dir = "positive",
                diff = ref_kendall - cor,
                n_na = (x_na + y_na) / 2)

realistic_negative_kt = realistic_negative_kt %>%
  dplyr::mutate(type = "ICI-Kt",
                dir = "negative",
                diff = ref_kendall_neg - cor,
                n_na = (x_na + y_na) / 2)

positive_df = rbind(realistic_positive_pearson,
                    realistic_positive_kendall,
                    realistic_positive_kt)

negative_df = rbind(realistic_negative_pearson,
                    realistic_negative_kendall,
                    realistic_negative_kt)

negative_df = negative_df %>%
  dplyr::mutate(perc_missing = n_na / max(n_na) * 100,
                type = factor(type, levels = c("Kendall", "Pearson", "ICI-Kt"), ordered = TRUE))
positive_df = positive_df %>%
  dplyr::mutate(perc_missing = n_na / max(n_na) * 100,
                type = factor(type, levels = c("Kendall", "Pearson", "ICI-Kt"), ordered = TRUE))
pos_diff = ggplot(positive_df, aes(x = n_na, y = diff)) + 
  geom_point() +
  facet_grid(type ~ ., scales = "free") +
  labs(subtitle = "Positive Correlation",
       x = "Number Missing",
       y = "Difference from Reference") +
  scale_y_continuous(labels = label_scientific(digits = 2)) +
  theme(plot.subtitle = element_text(size = 13))
neg_diff = ggplot(negative_df, aes(x = n_na, y = diff)) +
  geom_point() +
  facet_grid(type ~ ., scales = "free") +
  labs(subtitle = "Negative Correlation",
       x = "Number Missing",
       y = "Difference from Reference") +
  scale_y_continuous(labels = label_scientific(digits = 2)) +
  theme(plot.subtitle = element_text(size = 13))
pos_diff + neg_diff
```

**Fig X**. The effect on Kendall, Pearson and ICI-Kt correlations as increasing percentages in either or both samples are replaced with missing values for both positively and negatively correlated samples.

In **Figure X**, we can see that as missing values are added, only the ICI-Kt correlation values change in any significant way.
As the number of missing values increase, the ICI-Kt values drop or increase by up to 0.2.
Similarly, Pearson correlation is also affected, but the degree of change in the correlation values are much less (notice the difference in the y-axis scales), on the order of only 0.003 for the positive case and 0.1 for the negative case.

The lack of symmetry in the Pearson negative comparisons is due to the lack of linear correlation between the samples.

### Effect of Left Censoring VS Random Missing Data

```{r left_censored_vs_random, fig.height = 8, fig.width = 8}
loadd(left_censored_cor)
left_censored_cor = left_censored_cor %>%
  dplyr::mutate(which2 = dplyr::case_when(
    which %in% "ici" ~ "ICI-Kt",
    which %in% "kendall" ~ "Kendall",
    which %in% "kendall_0" ~ "Kendall-0",
    which %in% "pearson" ~ "Pearson",
    which %in% "pearson_0" ~ "Pearson-0"
  ))

loadd(random_censored_cor)

random_censored_cor = random_censored_cor %>%
  dplyr::mutate(censoring = "random") %>%
  dplyr::filter(n_na > 0) %>%
  dplyr::mutate(which2 = dplyr::case_when(
    which %in% "ici" ~ "ICI-Kt",
    which %in% "kendall" ~ "Kendall",
    which %in% "kendall_0" ~ "Kendall-0",
    which %in% "pearson" ~ "Pearson",
    which %in% "pearson_0" ~ "Pearson-0"
  ))

random_plot = ggplot(random_censored_cor, aes(x = n_na, y = cor)) +
  geom_sina(aes(group = n_na)) +
  facet_wrap(~ which2, nrow = 1) +
  labs(x = "Number Missing", y = "Correlation") +
  cowplot::panel_border()

rp_build = ggplot_build(random_plot)
rp_breaks = rp_build$layout$panel_params[[1]]$x$get_breaks()
rp_lim = rp_build$layout$panel_params[[1]]$x$get_limits()

left_plot = ggplot(left_censored_cor, aes(x = n_na, y = cor)) + 
  geom_point() + 
  facet_wrap(~ which2, nrow = 1) +
  labs(x = "Number Missing", y = "Correlation") +
  scale_x_continuous(breaks = c(0, 100, 200)) +
  cowplot::panel_border() 

(left_plot / random_plot) + plot_annotation(tag_levels = "A")
```

Figure X. Effect of introducing missing values from a cutoff or randomly on different measures of correlation, including ICI-Kt, Kendall with pairwise complete, Kendall replacing missing with 0, Pearson with pairwise complete, and Pearson replacing missing with 0.
A) Missing values introduced by setting an increasing cutoff.
B) Missing values introduced at random.
For the random case, each sample of random positions was repeated 100 times.

To evaluate the effect of introducing missingness in 

### Utility in Large Omics' Data Sets

#### Detecting Outlier Samples

We analyzed two RNA-Seq datasets for possible outliers using ICI-Kt.
The first is a collection of 56 samples in a cancer model and trying to determine differences in expression with and without EGFR as well as grown flat or as organoids.
ICI-Kt correlations were calculated using the genes that had a non-zero count in at least one of the samples.
For each sample, the median ICI-Kt value was calculated amongst the samples for each of the defined groups.
Two samples were found to have low correlations within their group.


```{r outlier_adenocarcinoma_setup}
loadd(ref_cor)
loadd(transcript_data)
adeno_cor = ref_cor$cor
adeno_info = readRDS(here::here("data", "recount_adeno_info.rds"))
adeno_cor = adeno_cor[adeno_info$sample_id2, adeno_info$sample_id2]

transcript_data = transcript_data[, adeno_info$sample_id2]
pearson_adeno_cor = cor(log1p(transcript_data))

med_cor = median_correlations(adeno_cor, sample_classes = adeno_info$sample_type)
p_med_cor = median_correlations(pearson_adeno_cor, sample_classes = adeno_info$sample_type)

split_med = split(med_cor, med_cor$sample_class)
split_p = split(p_med_cor, p_med_cor$sample_class)
cor_outlier = function(cor_df){
  out_vals = boxplot.stats(cor_df$med_cor)$out
  cor_df$sample_id[cor_df$med_cor %in% out_vals]
}
med_outliers = purrr::map(split_med, cor_outlier) %>% unlist()
med_cor$outlier = FALSE
med_cor[med_cor$sample_id %in% med_outliers, "outlier"] = TRUE
p_outliers = purrr::map(split_p, cor_outlier) %>% unlist()
p_med_cor$outlier = FALSE
p_med_cor[p_med_cor$sample_id %in% p_outliers, "outlier"] = TRUE
p_med_cor$correlation = "Pearson"
med_cor$correlation = "ICI-Kt"

all_med_cor = rbind(p_med_cor, med_cor)
all_med_cor = all_med_cor %>%
  dplyr::mutate(type2 = dplyr::case_when(
    grepl("Primary", sample_class) ~ "Tumor",
    grepl("Normal", sample_class) ~ "Normal"
  ))
```

The second is a collection of `r ncol(transcript_data)` adenocarcinoma samples from the TCGA project, and incorporated into the recount2 project [@collado-torres_recount2_2017].
In this dataset there are `r nrow(dplyr::filter(adeno_info, grepl("Normal", sample_type)))` normal and `r nrow(dplyr::filter(adeno_info, grepl("Tumor", sample_type)))` tumor samples.

From the pairwise sample-sample correlations, median correlations for each sample with all the other samples of the same class (normal or tumor) were calculated.
Outliers were determined using the boxplot.stats R function.

```{r plot_adenocarcinoma}
ggplot(all_med_cor, aes(x = type2, y = med_cor)) + 
  geom_sina(aes(color = outlier, group = sample_class)) +
  facet_wrap(~ correlation) +
  theme(legend.position = c(0.4, 0.2)) +
  labs(x = "Sample Type", y = "Median Correlation")
```

For the adenocarcinoma data, median correlations within the tumor and normal groups were calculated.
`r tools::toTitleCase(n2w(nrow(dplyr::filter(med_cor, outlier, grepl("Normal", sample_class)))))` sample in the Normal, and `r n2w(nrow(dplyr::filter(med_cor, outlier, grepl("Tumor", sample_class))))` outliers were found, whether using ICI-Kt correlation or Pearson correlation.

### Algorithmic Performance

We compared the performance of our Rcpp mergesort implementation to the base R cor function using both "pearson" and "kendall" methods on a single core with increasing numbers of features.

Figure X shows that the "kendall" method is the slowest by far.
Zoomed out, the ICI-Kt appears as fast as using "pearson", but upon zooming in, it's possible to see that ICI-Kt is using increasing amounts of time much faster than "pearson".
In fact, regressing the time to number of samples using a formula with the expected algorithmic complexity, "pearson" shows O(n), ICI-Kt is O(nlog(n)), and "kendall" is O(n^2) (see supplemental).

```{r show_performance_graph}
single_core_perf = readRDS(here::here("doc", "single_core_perf.rds"))
s_perf_plot = ggplot(single_core_perf, aes(x = n, y = time, color = method)) +
  geom_line(size = 2) + 
  coord_cartesian(ylim = c(NA, 0.002)) + 
  theme(legend.position = c(0.6, 0.2)) +
  labs(x = "Number of Features", y = "Time (s)")
#s_perf_plot

mod_perf = dplyr::filter(single_core_perf, method %in% "ici_kt")
mod_perf$time = mod_perf$time + 0.015
core_perf2 = bind_rows(
  mod_perf,
  dplyr::filter(single_core_perf, !(method %in% "ici_kt"))
)
inset_perf = ggplot(core_perf2, aes(x = n, y = time, color = method)) +
  geom_line(size = 1.5) +
  theme(legend.position = "none",
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  labs(x = "", y = "")

s_perf_plot + inset_element(inset_perf, 0.1, 0.72, 1, 1)
```

Figure X. Comparison of the Rcpp mergesort ici_kt, and base R's correlation function using the "pearson" and "kendall" methods as the number of features are increased from 100 to 5000.
Inset is the expanded view showing the full range of computation time in seconds.


### Multi-Processing Performance

In addition to an evaluation of the mergesort performance, we also wanted to evaluate the multi-processing performance.
For this, we ran with small numbers of samples **without** parallelization enabled, and then with larger numbers of samples **with** parallelization enabled.

```{r dependence_number}
loadd(combined_big)
combined_big = combined_big %>%
  dplyr::mutate(set = "large")

ggplot(combined_big, aes(x = n_sample, y = log2(time))) + 
  geom_line() +
  labs(x = "Number of Samples",
       y = "Log2(Time) (s)")
```

**Fig X**. Time taken by ICI-Kt as a function of the number of samples with multi-processing at the R level, using 80 cores.

As samples are added, the run time quickly increases logarithmically, similar to increasing samples on a single core.


### Feature Subsampling Randomly

```{r pretty_print}
pretty_print = function(in_val){
  sprintf(in_val, fmt = '%#.1f')
}
```

```{r load_data}
loadd(transcript_data)
loadd(ref_cor)
```

```{r load_ici_timings, fig.height = 8, fig.width = 5}
loadd(run_random_select_random_fraction_0.01)
loadd(run_random_select_random_fraction_0.1)
loadd(run_random_select_random_fraction_0.3)
diff_vals = data.frame(ref = extract_data(ref_cor),
                       f_01 = 
extract_data(run_random_select_random_fraction_0.01),
                     f_1 = extract_data(run_random_select_random_fraction_0.1),
                     f_3 = extract_data(run_random_select_random_fraction_0.3))
diff_vals = diff_vals %>%
  dplyr::mutate(diff_1 = f_01 - ref,
                diff_10 = f_1 - ref,
                diff_30 = f_3 - ref)
ref_f1_f3 = 
  ((ggplot(diff_vals, aes(x = ref, y = f_01)) + geom_point() +
     labs(x = "All Features", y = "1% Features") +
  coord_equal() +
    geom_abline(slope = 1, color = "red")) |
  (ggplot(diff_vals, aes(x = diff_1)) +
     geom_histogram(bins = 100) +
     labs(x = "Correlation Residual") +
     coord_cartesian(xlim = c(-0.03, 0.03)) +
     scale_y_continuous(expand = expansion(mult = 0)) +
     geom_vline(xintercept = 0, color = "red"))) /
  ((ggplot(diff_vals, aes(x = ref, y = f_1)) + geom_point() +
     labs(x = "All Features", y = "10% Features") +
     coord_equal() +
      geom_abline(slope = 1, color = "red")) | 
  (ggplot(diff_vals, aes(x = diff_10)) +
     geom_histogram(bins = 100) +
     labs(x = "Correlation Residual") +
     coord_cartesian(xlim = c(-0.03, 0.03)) +
     scale_y_continuous(expand = expansion(mult = 0)) +
     geom_vline(xintercept = 0, color = "red"))) /
  ((ggplot(diff_vals, aes(x = ref, y = f_3)) + geom_point() +
     labs(x = "All Features", y = "30% Features") +
     coord_equal() +
      geom_abline(slope = 1, color = "red")) +
  (ggplot(diff_vals, aes(x = diff_30)) +
     geom_histogram(bins = 100) +
     labs(x = "Correlation Residual") +
     coord_cartesian(xlim = c(-0.03, 0.03)) +
     scale_y_continuous(expand = expansion(mult = 0)) +
     geom_vline(xintercept = 0, color = "red")))

ref_f1_f3
```

Figure X. Sample-sample ICI-Kt correlations using all features compared with 1%, 10% and 30% random subsets of features. Left: The sample-sample correlations using all features are plotted against the sample-sample correlations using a random subset. Red line indicates perfect agreement. Right: Histogram of the residual differences of the sample-sample correlations, where the difference is the (random subset - all features).

Given the length of time it takes to run the calculations for larger datasets (in particular RNA-Seq data), we wondered if "good enough" results could be obtained using subsamples of the features across the samples.
Our starting data is a set of stage I (I, Ia, and Ib) adenocarcinoma tumor and normal tissue RNA-Seq samples from the *recount2* project, with `r nrow(transcript_data)` features that have a non-zero value in at least one sample, and `r ncol(transcript_data)` samples.

In our original Rcpp implementation with actual pairwise comparisons, the adenocarcinoma pairwise comparisons took 6.7 hours, on an 80 core virtual machine.
With the mergesort implementation, that time was greatly reduced to just over a minute (69 seconds).
However, given that there may still be cases where the number of comparisons are so large that run time is still a concern, we investigated the effect of estimating sample-sample correlations using a subset of the features.

Figure X compares the sample-sample correlations from a random percent subsample of features to those obtained using all of the features.
Both the pairwise plot (left) and histogram of residual differences (right) show that the correlations become much closer to those obtained when using all of the features as the percentage of subsampled features is increased.
However, there is a consistent positive bias in the estimate, regardless of the number of subsamples used.

### Deviations Based on Principal Component Coverage

As a further evaluation of the random feature subsampling, we used principal component coverage to discern how the random subsampling behaves (see Methods).
For each principal component, the coverage was evaluated as the fraction of the loadings accounted for by the subsampled features.
Further, the Kendall-tau correlation between the variance of the principal component and the fraction of loadings was calculated, as well as the median of the loading coverage across all principal components.
Figure X shows that for the random feature subsampling, Kendall-tau correlation implies no relationship between the loading fraction and the contributed variance of a PC, and the median of the loading fractions across PCs is close to the intended fraction of data accounted for.

```{r pca_eval}
loadd(pca_eval_summary)

rand_eval = pca_eval_summary %>%
  dplyr::filter(type %in% "random")

r_e_kt = ggplot(rand_eval, aes(x = frac, y = kt)) + 
geom_hline(yintercept = 0, color = "red") + 
  geom_point() +
  labs(x = "Subsample Fraction", y = "Kendall-tau")
r_e_diff = ggplot(rand_eval, aes(x = frac, y = diff_perc)) + 
  geom_hline(yintercept = 0, color = "red") +
  geom_point() +
  labs(x = "Subsample Fraction", y = "Percent Median Loading Fraction Difference")

rand_plot = r_e_kt | r_e_diff
rand_plot + plot_annotation(tag_levels = 'A')
```

Figure X. A) Subsampled feature fraction plotted against the Kendall-tau correlation between the loading fraction and the contributed variance of the PC.
Red line drawn at correlation of zero.
B) Subsampled feature fraction plotted against the percent difference of the median loading fraction to the intended loading fraction, which is also the subsample fraction.
Red line drawn at a difference of zero.

### Evaluation of Variance and PCA Based Subsampling

In addition to the random feature subsamples, we also implemented feature selection methods based on loading contributions to each PC, as well as feature variances in the full data set (see Methods).
As shown in Figure X, both of these feature selection methods perform extremely poorly, even at the relatively large fraction of 50% of the features.

```{r poor_pca_var}
loadd(run_nonrandom_select_nonrandom_fraction_0.5_var_select)
loadd(run_nonrandom_select_nonrandom_fraction_0.5_pca_select)
diff_var = data.frame(ref = extract_data(ref_cor),
                         f_50 = 
                           extract_data(run_nonrandom_select_nonrandom_fraction_0.5_var_select)) %>%
  dplyr::mutate(diff = f_50 - ref)
diff_pca = data.frame(ref = extract_data(ref_cor),
                      f_50 = extract_data(run_nonrandom_select_nonrandom_fraction_0.5_pca_select)) %>%
  dplyr::mutate(diff = f_50 - ref)

var_diff = ggplot(diff_var, aes(x = ref, y = f_50)) +
  geom_abline(slope = 1, color = "red") +
  geom_point() +
  coord_equal() +
  labs(x = "All Features",
       y = "50% Features by Variance")
pca_diff = ggplot(diff_pca, aes(x = ref, y = f_50)) +
  geom_abline(slope = 1, color = "red") +
  geom_point() +
  coord_equal() +
  labs(x = "All Features",
       y = "50% Features by PCA")
var_dist = ggplot(diff_var, aes(x = diff)) + 
  geom_histogram(bins = 100) + 
  labs(x = "Correlation Residual")
pca_dist = ggplot(diff_pca, aes(x = diff)) +
  geom_histogram(bins = 100) +
  labs(x = "Correlation Residual")

nonrandom_plot = (var_diff | var_dist) / (pca_diff | pca_dist)
nonrandom_plot
```

Figure X. Sample-sample ICI-Kt correlations using all features compared with 50% non-random subsets of features. 
Left: The sample-sample correlations using all features are plotted against the sample-sample correlations using 50% of features chosen by variance contribution or PCA. Red line indicates perfect agreement. 
Right: Histogram of the residual differences of the sample-sample correlations, where the difference is the (subset - all features).

We also used the same evaluation by loading fraction for the variance and PCA chosen feature subsamples.
Figure X shows that in both the variance and PCA subsamples, there is a relationship between the loading fraction and the contributed variance of a PC.

```{r nonrandom_pca}
nonrand_eval = pca_eval_summary %>%
  dplyr::filter(!(type %in% "random"))

nr_e_kt = ggplot(nonrand_eval, aes(x = frac, y = kt, color = type)) + 
  geom_point() +
  labs(x = "Subsample Fraction", y = "Kendall-tau") +
  theme(legend.position = "none")
nr_e_diff = ggplot(nonrand_eval, aes(x = frac, y = diff_perc, color = type)) + 
  geom_point() +
  labs(x = "Subsample Fraction", y = "Percent Median Loading Fraction Difference") +
  theme(legend.position = c(0.5, 0.8))

nonrand_eval_plot = nr_e_kt | nr_e_diff
nonrand_eval_plot + plot_annotation(tag_levels = 'A')
```

Figure X. A) Subsampled feature fraction plotted against the Kendall-tau correlation between the loading fraction and the contributed variance of the PC.
B) Subsampled feature fraction plotted against the percent difference of the median loading fraction to the intended loading fraction, which is also the subsample fraction.

## Discussion

???

## Conclusions

???

## Author Contributions

RMF wrote the code in the visualizationQualityControl R package, tested the ICI-Kt correlation code, and wrote all of the analysis code for this manuscript. HNBM conceived of the ICI-Kt correlation, provided input into code structures, provided supervision of the analyses and interpretation of results. Both authors contributed to the writing of the manuscript.

## Supplemental

The simplest simulated data set includes three samples, where two are perfectly correlated, and the third perfectly anti-correlated. 
We then created missing values (replaced value with NA) in each sample systematically, and computed the ICI-Kt, Pearson, and Kendall-tau correlations.

```{r compare_simple}
loadd(positive_kt)
loadd(positive_pearson)
positive_pearson[is.na(positive_pearson$cor), "cor"] = 0

compare_df = data.frame(ici_kt = positive_kt$cor,
                        pearson = positive_pearson$cor)
ggplot(compare_df, aes(x = pearson, y = ici_kt)) + geom_point()
```

In addition to comparing their performance, we can check that the algorithmic complexity fits the theoretically expected complexity by fitting a regression line of the run time to the number of items.

```{r plot_complexity}
complex_figure = create_complexity_figure(single_core_perf)
complex_figure
```

## Acknowledgements

The results shown here are in whole or part based upon data generated by the TCGA Research Network: https://www.cancer.gov/tcga.

## References
